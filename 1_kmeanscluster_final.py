# -*- coding: utf-8 -*-
"""1-kmeanscluster-final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-zIsGDxcr7Vng-AVG5JKWEmc1wMtoMBb
"""

# Commented out IPython magic to ensure Python compatibility.
# Import Library!
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import gc
import os
import warnings
from matplotlib import style

sns.set_style('whitegrid')
warnings.filterwarnings('ignore')
# %matplotlib inline

df=pd.read_csv("D:/Datasets/API_19_DS2_en_csv_v2_4773766.csv",skiprows=4)

df.sample(5)

df.info()

# listing all indicator names
print(df['Indicator Name'].unique())# _counts()) 'Indicator Code'

# listing all indicator codes
print(df['Indicator Code'].unique())

df.head()

#drop all null rows
df.dropna(how='all')

# importing necessary libraries
import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
from sklearn.cluster import KMeans

n_cluster=4

kmeans=KMeans(n_clusters=n_cluster,random_state=42)

"""# 1 indicator CO2 emissions (kg per PPP $ of GDP)"""

# selecting the data with the indicator CO2 emissions (kg per PPP $ of GDP)
df_1=df[df['Indicator Code']=='EN.ATM.CO2E.PP.GD']#'SP.POP.GROW']  #CO2 emissions (kg per PPP $ of GDP)

df_1.fillna(0,inplace=True)

df_1a=pd.DataFrame()

# creating clusters for the years 1993 and 2012.
df_1a['1993']=df_1['1993'].copy()
df_1a['2012']=df_1['2012'].copy()

# resetting the column index
df_1a.reset_index(drop=True)

df_1a.info()

from sklearn.preprocessing import StandardScaler
df_1a_colnam=df_1a.columns.values.tolist()

#create scaled DataFrame where each variable has mean of 0 and standard dev of 1
scaled_df_1 = StandardScaler().fit_transform(df_1a.to_numpy())

#creating the dataframe
scaled_df_1=pd.DataFrame(scaled_df_1, columns=[df_1a_colnam])

# kmeans=kmeans.fit(df_1.drop(['Country Name','Country Code','Indicator Name','Indicator Code'],axis=1))

scaled_df_1.head()

scaled_df_1.describe()

# changing the datatype
scaled_df_1 = scaled_df_1.astype(float)

# running k means clustering
kmeans=kmeans.fit(scaled_df_1)

#creating a duplicate dataframe
scaled_df_1a=scaled_df_1

# creating cluster ids
scaled_df_1a['clust_id']=kmeans.predict(scaled_df_1)

scaled_df_1a.head()

temp1a=pd.DataFrame()
temp1a['clust_id']=scaled_df_1a['clust_id'].copy()

temp1a.reset_index(drop=True, inplace=True)

df_1a.reset_index(drop=True, inplace=True)

df_1a_final=pd.concat([df_1a, temp1a], axis=1)
df_1a_final.head()

# deterining the labels 
labels = kmeans.labels_

#finding the centers of the clusters
cen = kmeans.cluster_centers_
print(cen)

import sklearn.metrics as skmet

# calculate the silhoutte score
print(skmet.silhouette_score(scaled_df_1a, labels))

# plot using the labels to select colour
plt.figure(figsize=(10.0, 10.0))

for l in range(n_cluster): # loop over the different labels
  plt.scatter(scaled_df_1a[labels==l][df_1a_colnam[0]], scaled_df_1a[labels==l][df_1a_colnam[1]])
  # plt.scatter(df_1a_final[labels==l][df_1a_colnam[0]], df_1a_final[labels==l][df_1a_colnam[1]])

# # show cluster centres
for ix in range(n_cluster):
  xc, yc = cen[ix,:]
  plt.plot(xc, yc, "dk", markersize=10)

plt.xlabel(df_1a_colnam[0])
plt.ylabel(df_1a_colnam[1])
plt.title('Clusters for the years 1993 and 2012 for the indicator-CO2 emissions (kg per PPP $ of GDP)')
plt.show()

"""# 2 indicator Electricity production from oil sources (% of total)"""

# selecting the data with the indicator Electricity production from oil sources (% of total)
df_2=df[df['Indicator Code']== 'EG.ELC.PETR.ZS']#EN.ATM.SF6G.KT.CE']#']

df_2.fillna(0,inplace=True)

df_2a=pd.DataFrame()

df_2a['1993']=df_2['1993'].copy()
df_2a['2012']=df_2['2012'].copy()

df_2a.reset_index(drop=True)

from sklearn.preprocessing import StandardScaler
df_2a_colnam=df_2a.columns.values.tolist()

scaled_df_2 = StandardScaler().fit_transform(df_2a.to_numpy())

#view first five rows of scaled DataFrame
# print(scaled_df.head())
scaled_df_2=pd.DataFrame(scaled_df_2, columns=[df_2a_colnam])

scaled_df_2.head()

scaled_df_2.describe()

scaled_df_2 = scaled_df_2.astype(float)

kmeans=kmeans.fit(scaled_df_2)

scaled_df_2a=scaled_df_2

scaled_df_2a['clust_id']=kmeans.predict(scaled_df_2)

labels = kmeans.labels_

cen = kmeans.cluster_centers_
print(cen)

import sklearn.metrics as skmet

# calculate the silhoutte score
print(skmet.silhouette_score(scaled_df_2a, labels))

# plot using the labels to select colour
plt.figure(figsize=(10.0, 10.0))

for l in range(n_cluster): # loop over the different labels
  plt.scatter(scaled_df_2a[labels==l][df_2a_colnam[0]], scaled_df_2a[labels==l][df_2a_colnam[1]])

# # show cluster centres
for ix in range(n_cluster):
  xc, yc = cen[ix,:]
  plt.plot(xc, yc, "dk", markersize=10)

plt.xlabel(df_2a_colnam[0])
plt.ylabel(df_2a_colnam[1])
plt.title('Clusters for the years 1993 and 2012 for the indicator-Electricity production from oil sources (% of total)')
plt.show()

"""# 3 indicator Access to electricity (% of population)"""

# selecting the data with the indicator Access to electricity (% of population)
df_3=df[df['Indicator Code']== 'EG.ELC.ACCS.ZS']

df_3.fillna(0,inplace=True)

df_3a=pd.DataFrame()

df_3a['1993']=df_3['1993'].copy()
df_3a['2012']=df_3['2012'].copy()

df_3a.reset_index(drop=True)

df_3a.info()

from sklearn.preprocessing import StandardScaler
df_3a_colnam=df_3a.columns.values.tolist()

scaled_df_3 = StandardScaler().fit_transform(df_3a.to_numpy())

#view first five rows of scaled DataFrame
# print(scaled_df.head())
scaled_df_3=pd.DataFrame(scaled_df_3, columns=[df_3a_colnam])

scaled_df_3.head()

scaled_df_2.describe()

scaled_df_3 = scaled_df_3.astype(float)

kmeans=kmeans.fit(scaled_df_3)

scaled_df_3a=scaled_df_3

scaled_df_3a['clust_id']=kmeans.predict(scaled_df_3)

scaled_df_3a.head()

labels = kmeans.labels_

cen = kmeans.cluster_centers_
print(cen)

import sklearn.metrics as skmet

# calculate the silhoutte score
print(skmet.silhouette_score(scaled_df_3a, labels))

# plot using the labels to select colour
plt.figure(figsize=(10.0, 10.0))

for l in range(n_cluster): # loop over the different labels
  plt.scatter(scaled_df_3a[labels==l][df_3a_colnam[0]], scaled_df_3a[labels==l][df_3a_colnam[1]])

# # show cluster centres
for ix in range(n_cluster):
  xc, yc = cen[ix,:]
  plt.plot(xc, yc, "dk", markersize=10)

plt.xlabel(df_3a_colnam[0])
plt.ylabel(df_3a_colnam[1])
plt.title('Clusters for the years 1993 and 2012 for the indicator-Access to electricity (% of population)')
plt.show()

"""# 4 indicator-Urban population (% of total population)"""

# selecting the data with the indicator-Urban population (% of total population)
df_4=df[df['Indicator Code']== 'SP.URB.TOTL.IN.ZS']

df_4.fillna(0,inplace=True)

df_4a=pd.DataFrame()

df_4a['1993']=df_4['1993'].copy()
df_4a['2016']=df_4['2016'].copy()

df_4a.reset_index(drop=True)

df_4a.info()

from sklearn.preprocessing import StandardScaler
df_4a_colnam=df_4a.columns.values.tolist()

scaled_df_4 = StandardScaler().fit_transform(df_4a.to_numpy())

#view first five rows of scaled DataFrame
# print(scaled_df.head())
scaled_df_4=pd.DataFrame(scaled_df_4, columns=[df_4a_colnam])

scaled_df_4.head()

scaled_df_4.describe()

scaled_df_4 = scaled_df_4.astype(float)

kmeans=kmeans.fit(scaled_df_4)

scaled_df_4a=scaled_df_4

scaled_df_4a['clust_id']=kmeans.predict(scaled_df_4)

scaled_df_4a.head()

labels = kmeans.labels_

cen = kmeans.cluster_centers_
print(cen)

import sklearn.metrics as skmet

# calculate the silhoutte score
print(skmet.silhouette_score(scaled_df_4a, labels))

# plot using the labels to select colour
plt.figure(figsize=(10.0, 10.0))

for l in range(n_cluster): # loop over the different labels
  plt.scatter(scaled_df_4a[labels==l][df_4a_colnam[0]], scaled_df_4a[labels==l][df_4a_colnam[1]])

# # show cluster centres
for ix in range(n_cluster):
  xc, yc = cen[ix,:]
  plt.plot(xc, yc, "dk", markersize=10)

plt.xlabel(df_4a_colnam[0])
plt.ylabel(df_4a_colnam[1])
plt.title('Clusters for the years 1993 and 2012 for the indicator-Urban population (% of total population)')
plt.show()

"""# 5 Indicator Forest area (% of land area)"""



# selecting the data with the indicator-Forest area (% of land area)
df_5=df[df['Indicator Code']== 'AG.LND.FRST.ZS']

df_5.fillna(0,inplace=True)

df_5a=pd.DataFrame()

df_5a['1993']=df_5['1993'].copy()
df_5a['2016']=df_5['2016'].copy()

df_5a.reset_index(drop=True)

df_5a.info()

from sklearn.preprocessing import StandardScaler
df_5a_colnam=df_5a.columns.values.tolist()

scaled_df_5 = StandardScaler().fit_transform(df_5a.to_numpy())

#view first five rows of scaled DataFrame
# print(scaled_df.head())
scaled_df_5=pd.DataFrame(scaled_df_5, columns=[df_5a_colnam])

scaled_df_5.head()

scaled_df_5.describe()

scaled_df_5 = scaled_df_5.astype(float)

kmeans=kmeans.fit(scaled_df_5)

scaled_df_5a=scaled_df_5

scaled_df_5a['clust_id']=kmeans.predict(scaled_df_5)

labels = kmeans.labels_

cen = kmeans.cluster_centers_
print(cen)

import sklearn.metrics as skmet

# calculate the silhoutte score
print(skmet.silhouette_score(scaled_df_5a, labels))

# plot using the labels to select colour
plt.figure(figsize=(10.0, 10.0))

for l in range(n_cluster): # loop over the different labels
  plt.scatter(scaled_df_5a[labels==l][df_5a_colnam[0]], scaled_df_5a[labels==l][df_5a_colnam[1]])

# # show cluster centres
for ix in range(n_cluster):
  xc, yc = cen[ix,:]
  plt.plot(xc, yc, "dk", markersize=10)

plt.xlabel(df_5a_colnam[0])
plt.ylabel(df_5a_colnam[1])
plt.title('Clusters for the years 1993 and 2012 for the indicator-Forest area (% of land area)')
plt.show()

"""# Choosing albania with the indicator CO2 emissions (kg per PPP $ of GDP) FOR CURVE FITTING"""

x1=pd.DataFrame()
x1[0]=df_1.iloc[5]
x1[1]=df_1.iloc[3]
print(x1)

x1.info()

# x1=x1.T
# x1.drop(['Unnamed: 66'],axis=1)#,Inplace=True)
x1.head()

x1t=x1.T
x1t.head()



x1_c=x1.T
#  x1_cs= 
#  x1.iloc[:,3]=list(x1_c.columns)
x1['year']=list(x1_c.columns)
x1.head()
# print(list(x1_c.columns))

x1.drop(['Country Name','Country Code','Indicator Name','Indicator Code','Unnamed: 66'],axis=0,inplace=True)

x1.rename(columns = {'0':'Albania','1':'Africa Western and Central'}, inplace = True)

x1.reset_index(drop=True,inplace=True)
x1.head()

x1.rename(columns = {'0':'Albania','1':'Africa Western and Central'}, inplace = True)

x1a=x1.T
x1a.reset_index()
x1a.head()

# tempx1=pd.DataFrame()
# tempx1=x1.iloc[4:67,1]
# tempx1[:,0]

x1.info()

pp_b=x1.iloc[:,2].iloc[33:66]#iloc[:,2].iloc[33:66]#iloc[33:66].iloc[:,2]
pp_b=pp_b.astype(float)

plt.hist(pp_b)

# Function to calculate the linear with constants a and b
def linear(x, a, b):
    # return a*np.exp(b*x)
    return a*x+b

# Calculate y-values based on dummy x-----------------------np.array([[1, 2, 3], [5, 0, 0]], dtype=object)
# y_dummy = exponential(np.array(x1.iloc[1,:].iloc[34:63],dtype=object), 0.5, 0.5)
y_dummy = linear(np.array(pp_b), -0.5, 0.25)

# Import curve fitting package from scipy
from scipy.optimize import curve_fit

# Fit the dummy exponential data
pars, cov = curve_fit(f=linear, xdata=pp_b, ydata=y_dummy, p0=[0, 0], bounds=(-np.inf, np.inf))

# Plot the noisy exponential data
plt.scatter(pp_b, y_dummy, s=20, color='#00b3b3', label='Data')
plt.plot(pp_b, linear(pp_b, *pars), linestyle='--', linewidth=2, color='red',label='Fit')